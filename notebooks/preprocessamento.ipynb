{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6aa3d9f",
   "metadata": {},
   "source": [
    "Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ce4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir informações universais \n",
    "caminho_pdf_selecionado = \"../data/input/RCG2025.pdf\"\n",
    "caminho_data_input=\"../data/input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81e4a2",
   "metadata": {},
   "source": [
    "Extração de texto bruto: remover cabeçalhos, rodapés, numeração de páginas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e654a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir pdfs e extrair texto bruto\n",
    "if os.path.exists(caminho_pdf_selecionado):\n",
    "    print(f\"Arquivo encontrado: {caminho_pdf_selecionado}\")\n",
    "    texto_bruto = \"\"\n",
    "    with pdfplumber.open(caminho_pdf_selecionado) as pdf:\n",
    "        print(f\"Total de páginas: {len(pdf.pages)}\")\n",
    "        for i, pagina in enumerate(pdf.pages):\n",
    "            print(f\"Processando página {i+1}...\")\n",
    "            texto_pagina = pagina.extract_text()\n",
    "            if texto_pagina:\n",
    "                texto_bruto += texto_pagina + \"\\n\"\n",
    "else:\n",
    "    print(f\"ERRO: Arquivo não encontrado: {caminho_pdf_selecionado}\")\n",
    "    print(\"Arquivos disponíveis:\")\n",
    "    for arquivo in os.listdir(caminho_data_input):\n",
    "        print(f\"  - {arquivo}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e289620",
   "metadata": {},
   "source": [
    "Normalização linguística: padronizar texto e expandir siglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tudo minúsculo\n",
    "texto_limpo = texto_bruto.lower()  \n",
    "# remove quebras de linha repetidas\n",
    "texto_limpo = re.sub(r'\\n+', ' ', texto_limpo)  \n",
    "# remove espaços extras\n",
    "texto_limpo = re.sub(r'\\s+', ' ', texto_limpo)  \n",
    "# remove números\n",
    "texto_limpo = re.sub(r'\\d+', '', texto_limpo) \n",
    "# remove pontuação \n",
    "texto_limpo = re.sub(r'[^\\w\\s]', '', texto_limpo)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4878c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove acentos\n",
    "texto_normalizado = unidecode.unidecode(texto_limpo)  \n",
    "texto_normalizado = texto_normalizado.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aabc09",
   "metadata": {},
   "source": [
    "Expansão de siglas e abreviações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de substituições\n",
    "substituicoes = {\n",
    "    \"tcc\": \"trabalho de conclusão de curso\",\n",
    "    \"sgbd\": \"sistema de gerenciamento de banco de dados\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddce80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandir_siglas(texto, substituicoes):\n",
    "    for sigla, expansao in substituicoes.items():\n",
    "        # \\b garante que a troca ocorre apenas em palavras inteiras\n",
    "        texto = re.sub(rf'\\b{sigla}\\b', expansao, texto)\n",
    "    return texto\n",
    "\n",
    "texto_normalizado = expandir_siglas(texto_normalizado, substituicoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f7de6",
   "metadata": {},
   "source": [
    "Detecção de estrutura: identificar capítulos, seções, artigos, parágrafos, incisos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padroes = {\n",
    "    \"capitulo\": r'cap[ií]tulo\\s+[ivxlcdm]+',\n",
    "    \"secao\": r'se[cç][aã]o\\s+[ivxlcdm]+',\n",
    "    # \"artigo\": r'art\\.?\\s*\\d+[º°]?',\n",
    "    # \"paragrafo\": r'§\\s*\\d+[º°]?',\n",
    "    # \"inciso\": r'^[ivxlcdm]+\\s*[-–)]',\n",
    "}\n",
    "\n",
    "for tipo, regex in padroes.items():\n",
    "    resultados = re.findall(regex, texto_normalizado, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    print(f\"{tipo.title()}: {resultados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e049f75",
   "metadata": {},
   "source": [
    "Extração de tabelas: converter tabelas do PDF em formato estruturado (linhas e colunas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54817e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "caminho_pdf = \"../data/input/RCG2025.pdf\"\n",
    "tabelas_extraidas = []\n",
    "\n",
    "with pdfplumber.open(caminho_pdf) as pdf:\n",
    "    for pagina in pdf.pages:\n",
    "        tabelas = pagina.extract_tables()\n",
    "        for tabela in tabelas:\n",
    "            df = pd.DataFrame(tabela[1:], columns=tabela[0])  # primeira linha = cabeçalho\n",
    "            tabelas_extraidas.append(df)\n",
    "\n",
    "# Exemplo: visualizar a primeira tabela\n",
    "print(tabelas_extraidas[0].head())\n",
    "\n",
    "# Salvar em CSV\n",
    "tabelas_extraidas[0].to_csv(\"tabela1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0acd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "tabelas_extraidas = []\n",
    "\n",
    "with pdfplumber.open(\"../data/input/RCG2025.pdf\") as pdf:\n",
    "    for i, pagina in enumerate(pdf.pages, start=1):\n",
    "        tabelas = pagina.extract_tables()\n",
    "        for t in tabelas:\n",
    "            df = pd.DataFrame(t[1:], columns=t[0])  # primeira linha = cabeçalho\n",
    "            tabelas_extraidas.append(df)\n",
    "            print(f\"Tabela encontrada na página {i}:\")\n",
    "            print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nTexto extraído ({len(texto_normalizado)} caracteres):\")\n",
    "print(texto_normalizado[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac9b73",
   "metadata": {},
   "source": [
    "Deduplicação e consistência: eliminar trechos redundantes ou repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb00427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicação de linhas idênticas\n",
    "linhas = texto_normalizado.splitlines()\n",
    "linhas_unicas = list(dict.fromkeys(linhas))  # mantém ordem, remove duplicadas\n",
    "texto_deduplicado = \"\\n\".join(linhas_unicas)\n",
    "\n",
    "# Deduplicação aproximada (similaridade textual)\n",
    "import difflib\n",
    "\n",
    "linhas_unicas = []\n",
    "for linha in linhas:\n",
    "    if not linhas_unicas or difflib.SequenceMatcher(None, linha, linhas_unicas[-1]).ratio() < 0.9:\n",
    "        linhas_unicas.append(linha)\n",
    "\n",
    "texto_deduplicado = \"\\n\".join(linhas_unicas)\n",
    "\n",
    "# Remoção de cabeçalhos e rodapés automáticos\n",
    "# Usar expressões regulares para eliminar padrões previsíveis:\n",
    "texto_deduplicado = re.sub(r'p[áa]gina\\s*\\d+\\s*(de\\s*\\d+)?', '', texto_deduplicado, flags=re.IGNORECASE)\n",
    "texto_deduplicado = re.sub(r'minist[eé]rio da educa[cç][aã]o', '', texto_deduplicado, flags=re.IGNORECASE)\n",
    "\n",
    "# Normalização de consistência textual\n",
    "texto_final = re.sub(r'\\s+', ' ', texto_deduplicado).strip()\n",
    "\n",
    "# Deduplicação em nível de parágrafo\n",
    "paragrafos = [p.strip() for p in texto_deduplicado.split('\\n\\n') if p.strip()]\n",
    "paragrafos_unicos = list(dict.fromkeys(paragrafos))\n",
    "texto_final = '\\n\\n'.join(paragrafos_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a858a3",
   "metadata": {},
   "source": [
    "Enriquecimento com metadados: acrescentar informações como doc_id, nome_doc, versão, data_publicação, páginas inicial e final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extração automática de metadados do PDF \n",
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "\n",
    "arquivo = Path(\"documento.pdf\")\n",
    "\n",
    "with pdfplumber.open(arquivo) as pdf:\n",
    "    info_pdf = pdf.metadata\n",
    "    num_paginas = len(pdf.pages)\n",
    "\n",
    "print(info_pdf)\n",
    "\n",
    "# Criar o dicionário de metadados\n",
    "from datetime import datetime\n",
    "\n",
    "metadados = {\n",
    "    \"doc_id\": \"DOC_001\",\n",
    "    \"nome_doc\": arquivo.name,\n",
    "    \"versao\": \"1.0\",\n",
    "    \"data_publicacao\": datetime.strptime(\"2024-04-10\", \"%Y-%m-%d\").date(),\n",
    "    \"paginas_inicial\": 1,\n",
    "    \"paginas_final\": num_paginas,\n",
    "    \"autor\": info_pdf.get(\"/Author\"),\n",
    "    \"titulo\": info_pdf.get(\"/Title\"),\n",
    "}\n",
    "\n",
    "# Combinar texto + metadados\n",
    "documento = {\n",
    "    \"metadados\": metadados,\n",
    "    \"texto_limpo\": texto_final\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"documento_processado.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(documento, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Se estiver processando vários PDFs\n",
    "# Montar uma lista de documentos enriquecidos\n",
    "import glob\n",
    "\n",
    "todos_docs = []\n",
    "\n",
    "for caminho in glob.glob(\"pdfs/*.pdf\"):\n",
    "    with pdfplumber.open(caminho) as pdf:\n",
    "        texto = \"\\n\".join(pagina.extract_text() for pagina in pdf.pages if pagina.extract_text())\n",
    "        doc = {\n",
    "            \"metadados\": {\n",
    "                \"doc_id\": Path(caminho).stem.upper(),\n",
    "                \"nome_doc\": Path(caminho).name,\n",
    "                \"versao\": \"1.0\",\n",
    "                \"data_publicacao\": None,  # pode ser extraída depois\n",
    "                \"paginas_inicial\": 1,\n",
    "                \"paginas_final\": len(pdf.pages),\n",
    "            },\n",
    "            \"texto_limpo\": texto\n",
    "        }\n",
    "        todos_docs.append(doc)\n",
    "\n",
    "# Estrutura final sugerida (JSON)\n",
    "{\n",
    "  \"doc_id\": \"DOC_001\",\n",
    "  \"nome_doc\": \"relatorio_2024.pdf\",\n",
    "  \"versao\": \"1.0\",\n",
    "  \"data_publicacao\": \"2024-04-10\",\n",
    "  \"paginas_inicial\": 1,\n",
    "  \"paginas_final\": 25,\n",
    "  \"autor\": \"Ministério da Economia\",\n",
    "  \"titulo\": \"Relatório Anual 2024\",\n",
    "  \"texto_limpo\": \"conteúdo limpo e deduplicado do PDF...\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
